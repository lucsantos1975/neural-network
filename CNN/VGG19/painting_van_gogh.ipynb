{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "#import scipy.misc\n",
    "import scipy.io\n",
    "import imageio\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from sys import stderr\n",
    "from functools import reduce\n",
    "import time  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inputs \n",
    "file_content_image = 'Luciano_Santos_Self-Portrait_mini.jpg'\n",
    "file_style_image = 'Vincent_van_Gogh_Self-Portrait_mini.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters \n",
    "input_noise = 0.1     # proportion noise to apply to content image\n",
    "weight_style = 2e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Layers\n",
    "layer_content = 'conv4_2' \n",
    "layers_style = ['conv1_1', 'conv2_1', 'conv3_1', 'conv4_1', 'conv5_1']\n",
    "layers_style_weights = [0.2,0.2,0.2,0.2,0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VGG19 model\n",
    "## Download from: http://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-19.mat\n",
    "path_VGG19 = 'imagenet-vgg-verydeep-19.mat'\n",
    "# VGG19 mean for standardisation (RGB)\n",
    "VGG19_mean = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reporting & writing checkpoint images\n",
    "# NB. the total # of iterations run will be n_checkpoints * n_iterations_checkpoint\n",
    "n_checkpoints = 10             # number of checkpoints\n",
    "n_iterations_checkpoint = 10   # learning iterations per checkpoint\n",
    "path_output = 'output'         # directory to write checkpoint images into"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper functions\n",
    "def imread(path):\n",
    "    #return scipy.misc.imread(path).astype(np.float)   # returns RGB format\n",
    "    return imageio.imread(path).astype(np.float)\n",
    "\n",
    "def imsave(path, img):\n",
    "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    #scipy.misc.imsave(path, img)\n",
    "    imageio.imsave(path, img)\n",
    "    \n",
    "def imgpreprocess(image):\n",
    "    image = image[np.newaxis,:,:,:]\n",
    "    return image - VGG19_mean\n",
    "\n",
    "def imgunprocess(image):\n",
    "    temp = image + VGG19_mean\n",
    "    return temp[0] \n",
    "\n",
    "# function to convert 2D greyscale to 3D RGB\n",
    "def to_rgb(im):\n",
    "    w, h = im.shape\n",
    "    ret = np.empty((w, h, 3), dtype=np.uint8)\n",
    "    ret[:, :, 0] = im\n",
    "    ret[:, :, 1] = im\n",
    "    ret[:, :, 2] = im\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocessing\n",
    "# create output directory\n",
    "if not os.path.exists(path_output):\n",
    "    os.mkdir(path_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in images\n",
    "img_content = imread(file_content_image) \n",
    "img_style = imread(file_style_image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert if greyscale\n",
    "if len(img_content.shape)==2:\n",
    "    img_content = to_rgb(img_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(img_style.shape)==2:\n",
    "    img_style = to_rgb(img_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize style image to match content\n",
    "#img_style = imageio.imresize(img_style, img_content.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply noise to create initial \"canvas\" \n",
    "noise = np.random.uniform(\n",
    "        img_content.mean()-img_content.std(), img_content.mean()+img_content.std(),\n",
    "        (img_content.shape)).astype('float32')\n",
    "img_initial = noise * input_noise + img_content * (1 - input_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess each\n",
    "img_content = imgpreprocess(img_content)\n",
    "img_style = imgpreprocess(img_style)\n",
    "img_initial = imgpreprocess(img_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### BUILD VGG19 MODEL\n",
    "## with thanks to http://www.chioka.in/tensorflow-implementation-neural-algorithm-of-artistic-style\n",
    "\n",
    "VGG19 = scipy.io.loadmat(path_VGG19)\n",
    "VGG19_layers = VGG19['layers'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help functions\n",
    "def _conv2d_relu(prev_layer, n_layer, layer_name):\n",
    "    # get weights for this layer:\n",
    "    weights = VGG19_layers[n_layer][0][0][2][0][0]\n",
    "    W = tf.constant(weights)\n",
    "    bias = VGG19_layers[n_layer][0][0][2][0][1]\n",
    "    b = tf.constant(np.reshape(bias, (bias.size)))\n",
    "    # create a conv2d layer\n",
    "    conv2d = tf.nn.conv2d(prev_layer, filter=W, strides=[1, 1, 1, 1], padding='SAME') + b    \n",
    "    # add a ReLU function and return\n",
    "    return tf.nn.relu(conv2d)\n",
    "\n",
    "def _avgpool(prev_layer):\n",
    "    return tf.nn.avg_pool(prev_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/luciano/Workspace/neural-network/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Setup network\n",
    "with tf.Session() as sess:\n",
    "    a, h, w, d     = img_content.shape\n",
    "    net = {}\n",
    "    net['input']   = tf.Variable(np.zeros((a, h, w, d), dtype=np.float32))\n",
    "    net['conv1_1']  = _conv2d_relu(net['input'], 0, 'conv1_1')\n",
    "    net['conv1_2']  = _conv2d_relu(net['conv1_1'], 2, 'conv1_2')\n",
    "    net['avgpool1'] = _avgpool(net['conv1_2'])\n",
    "    net['conv2_1']  = _conv2d_relu(net['avgpool1'], 5, 'conv2_1')\n",
    "    net['conv2_2']  = _conv2d_relu(net['conv2_1'], 7, 'conv2_2')\n",
    "    net['avgpool2'] = _avgpool(net['conv2_2'])\n",
    "    net['conv3_1']  = _conv2d_relu(net['avgpool2'], 10, 'conv3_1')\n",
    "    net['conv3_2']  = _conv2d_relu(net['conv3_1'], 12, 'conv3_2')\n",
    "    net['conv3_3']  = _conv2d_relu(net['conv3_2'], 14, 'conv3_3')\n",
    "    net['conv3_4']  = _conv2d_relu(net['conv3_3'], 16, 'conv3_4')\n",
    "    net['avgpool3'] = _avgpool(net['conv3_4'])\n",
    "    net['conv4_1']  = _conv2d_relu(net['avgpool3'], 19, 'conv4_1')\n",
    "    net['conv4_2']  = _conv2d_relu(net['conv4_1'], 21, 'conv4_2')     \n",
    "    net['conv4_3']  = _conv2d_relu(net['conv4_2'], 23, 'conv4_3')\n",
    "    net['conv4_4']  = _conv2d_relu(net['conv4_3'], 25, 'conv4_4')\n",
    "    net['avgpool4'] = _avgpool(net['conv4_4'])\n",
    "    net['conv5_1']  = _conv2d_relu(net['avgpool4'], 28, 'conv5_1')\n",
    "    net['conv5_2']  = _conv2d_relu(net['conv5_1'], 30, 'conv5_2')\n",
    "    net['conv5_3']  = _conv2d_relu(net['conv5_2'], 32, 'conv5_3')\n",
    "    net['conv5_4']  = _conv2d_relu(net['conv5_3'], 34, 'conv5_4')\n",
    "    net['avgpool5'] = _avgpool(net['conv5_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONTENT LOSS: FUNCTION TO CALCULATE AND INSTANTIATION\n",
    "# with thanks to https://github.com/cysmith/neural-style-tf\n",
    "\n",
    "# Recode to be simpler: http://www.chioka.in/tensorflow-implementation-neural-algorithm-of-artistic-style\n",
    "def content_layer_loss(p, x):\n",
    "    _, h, w, d = [i.value for i in p.get_shape()]    # d: number of filters; h,w : height, width\n",
    "    M = h * w \n",
    "    N = d \n",
    "    K = 1. / (2. * N**0.5 * M**0.5)\n",
    "    loss = K * tf.reduce_sum(tf.pow((x - p), 2))\n",
    "    return loss\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(net['input'].assign(img_content))\n",
    "    p = sess.run(net[layer_content])  # Get activation output for content layer\n",
    "    x = net[layer_content]\n",
    "    p = tf.convert_to_tensor(p)\n",
    "    content_loss = content_layer_loss(p, x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STYLE LOSS: FUNCTION TO CALCULATE AND INSTANTIATION\n",
    "\n",
    "def style_layer_loss(a, x):\n",
    "    _, h, w, d = [i.value for i in a.get_shape()]\n",
    "    M = h * w \n",
    "    N = d \n",
    "    A = gram_matrix(a, M, N)\n",
    "    G = gram_matrix(x, M, N)\n",
    "    loss = (1./(4 * N**2 * M**2)) * tf.reduce_sum(tf.pow((G - A), 2))\n",
    "    return loss\n",
    "\n",
    "def gram_matrix(x, M, N):\n",
    "    F = tf.reshape(x, (M, N))                   \n",
    "    G = tf.matmul(tf.transpose(F), F)\n",
    "    return G\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(net['input'].assign(img_style))\n",
    "    style_loss = 0.\n",
    "    # style loss is calculated for each style layer and summed\n",
    "    for layer, weight in zip(layers_style, layers_style_weights):\n",
    "        a = sess.run(net[layer])\n",
    "        x = net[layer]\n",
    "        a = tf.convert_to_tensor(a)\n",
    "        style_loss += style_layer_loss(a, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/luciano/Workspace/neural-network/venv/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 6010497024.000000\n",
      "  Number of iterations: 10\n",
      "  Number of functions evaluations: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 10/100\n",
      "  content loss: 4.38714e+07\n",
      "    style loss: 5.96663e+09\n",
      "    total loss: 6.0105e+09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 990222464.000000\n",
      "  Number of iterations: 10\n",
      "  Number of functions evaluations: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 20/100\n",
      "  content loss: 4.81126e+07\n",
      "    style loss: 9.4211e+08\n",
      "    total loss: 9.90222e+08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 471465120.000000\n",
      "  Number of iterations: 10\n",
      "  Number of functions evaluations: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 30/100\n",
      "  content loss: 4.93337e+07\n",
      "    style loss: 4.22131e+08\n",
      "    total loss: 4.71465e+08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 323437952.000000\n",
      "  Number of iterations: 10\n",
      "  Number of functions evaluations: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 40/100\n",
      "  content loss: 4.99882e+07\n",
      "    style loss: 2.7345e+08\n",
      "    total loss: 3.23438e+08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 245167360.000000\n",
      "  Number of iterations: 10\n",
      "  Number of functions evaluations: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 50/100\n",
      "  content loss: 4.98e+07\n",
      "    style loss: 1.95367e+08\n",
      "    total loss: 2.45167e+08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 207190576.000000\n",
      "  Number of iterations: 10\n",
      "  Number of functions evaluations: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 60/100\n",
      "  content loss: 5.0009e+07\n",
      "    style loss: 1.57182e+08\n",
      "    total loss: 2.07191e+08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 171096384.000000\n",
      "  Number of iterations: 10\n",
      "  Number of functions evaluations: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 70/100\n",
      "  content loss: 4.99006e+07\n",
      "    style loss: 1.21196e+08\n",
      "    total loss: 1.71096e+08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 151736864.000000\n",
      "  Number of iterations: 10\n",
      "  Number of functions evaluations: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 80/100\n",
      "  content loss: 4.99009e+07\n",
      "    style loss: 1.01836e+08\n",
      "    total loss: 1.51737e+08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 135454288.000000\n",
      "  Number of iterations: 10\n",
      "  Number of functions evaluations: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 90/100\n",
      "  content loss: 4.96825e+07\n",
      "    style loss: 8.57718e+07\n",
      "    total loss: 1.35454e+08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
      "  Objective function value: 124013296.000000\n",
      "  Number of iterations: 10\n",
      "  Number of functions evaluations: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 100/100\n",
      "  content loss: 4.96717e+07\n",
      "    style loss: 7.43416e+07\n",
      "    total loss: 1.24013e+08\n"
     ]
    }
   ],
   "source": [
    "### Define loss function and minimise\n",
    "with tf.Session() as sess:\n",
    "    # loss function\n",
    "    L_total  = content_loss + weight_style * style_loss \n",
    "    \n",
    "    # instantiate optimiser\n",
    "    optimizer = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "      L_total, method='L-BFGS-B',\n",
    "      options={'maxiter': n_iterations_checkpoint})\n",
    "    \n",
    "    init_op = tf.initialize_all_variables()\n",
    "    sess.run(init_op)\n",
    "    sess.run(net['input'].assign(img_initial))\n",
    "    for i in range(1,n_checkpoints+1):\n",
    "        # run optimisation\n",
    "        optimizer.minimize(sess)\n",
    "        \n",
    "        ## print costs\n",
    "        stderr.write('Iteration %d/%d\\n' % (i*n_iterations_checkpoint, n_checkpoints*n_iterations_checkpoint))\n",
    "        stderr.write('  content loss: %g\\n' % sess.run(content_loss))\n",
    "        stderr.write('    style loss: %g\\n' % sess.run(weight_style * style_loss))\n",
    "        stderr.write('    total loss: %g\\n' % sess.run(L_total))\n",
    "\n",
    "        ## write image\n",
    "        img_output = sess.run(net['input'])\n",
    "        img_output = imgunprocess(img_output)\n",
    "        timestr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_file = path_output+'/'+timestr+'_'+'%s.jpg' % (i*n_iterations_checkpoint)\n",
    "        imsave(output_file, img_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
